{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Building_Neural_Nets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNYeNWQCCPklzA8jGtEzHHj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Oreolorun/NeuralNetsPractice/blob/main/Building_Neural_Nets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ryGN15bPYVpF"
      },
      "outputs": [],
      "source": [
        "#  Importing libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torchvision\n",
        "from torchvision import transforms, datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Torch Datasets"
      ],
      "metadata": {
        "id": "qT7J2mTE1tB7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  loading training data\n",
        "train_ds = datasets.MNIST(root='data/', train=True, download=True,\n",
        "                          transform=transforms.Compose([transforms.ToTensor()]))\n",
        "#  loading test data\n",
        "test_ds = datasets.MNIST(root='data/', train=False, download=True,\n",
        "                          transform=transforms.Compose([transforms.ToTensor()]))"
      ],
      "metadata": {
        "id": "QCrjj7z6ZqLD"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Splitting Function"
      ],
      "metadata": {
        "id": "Mk0my86L14PB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  creating split function\n",
        "def split_train_ds(dataset, val_pct):\n",
        "  #  size of dataset\n",
        "  size_ds = len(dataset)\n",
        "  #  desired size of validation set\n",
        "  size_val = int(size_ds*val_pct)\n",
        "  #  creating random permutations\n",
        "  perm = np.random.permutation(size_ds)\n",
        "  return perm[:size_val], perm[size_val:]\n",
        "\n",
        "val_indices, train_indices = split_train_ds(train_ds, 0.2) "
      ],
      "metadata": {
        "id": "JXknSCRPa9Uz"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating Sampler and Loading Data"
      ],
      "metadata": {
        "id": "IGQnWi-O19Vy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from torch.utils.data.dataloader import DataLoader\n",
        "\n",
        "#  creating samplers\n",
        "train_sampler = SubsetRandomSampler(train_indices)\n",
        "val_sampler = SubsetRandomSampler(val_indices)\n",
        "\n",
        "batch_size=10\n",
        "#  creating loaders\n",
        "train_dl = DataLoader(train_ds, sampler=train_sampler, batch_size=batch_size)\n",
        "valid_dl = DataLoader(train_ds, sampler=val_sampler, batch_size=batch_size,)\n",
        "test_dl = DataLoader(test_ds, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "MokCBrZAcfx1"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking for Imbalance"
      ],
      "metadata": {
        "id": "Bfk8dzF12Fxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  checking for class imbalance\n",
        "counter_dict = {0:0,1:0,2:0,3:0,4:0,5:0,6:0,7:0,8:0,9:0}\n",
        "for img, label in train_dl:\n",
        "  for lab in label:\n",
        "    counter_dict[int(lab)]+=1\n",
        "\n",
        "counter_dict"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9K3R7sY2osd0",
        "outputId": "5a75cbf6-5af8-4828-cb9b-f314810fffed"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 4721,\n",
              " 1: 5367,\n",
              " 2: 4768,\n",
              " 3: 4935,\n",
              " 4: 4662,\n",
              " 5: 4338,\n",
              " 6: 4709,\n",
              " 7: 5012,\n",
              " 8: 4726,\n",
              " 9: 4762}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Defining The Network"
      ],
      "metadata": {
        "id": "0K-cH56Z1hna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "class NeuralNet(nn.Module):\n",
        "  \"\"\"This class models a neural network\"\"\"\n",
        "  \n",
        "  def __init__(self):\n",
        "    \"\"\"An initialisation method which \n",
        "    inherits from the parent class nn.Module.\n",
        "    This is also where network layers are defined\"\"\"\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(784,64)\n",
        "    self.fc2 = nn.Linear(64,64)\n",
        "    self.fc3 = nn.Linear(64,64)\n",
        "    self.fc4 = nn.Linear(64,10)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 784)\n",
        "    x = F.relu(self.fc1(x))\n",
        "    x = F.relu(self.fc2(x))\n",
        "    x = F.relu(self.fc3(x))\n",
        "    x = self.fc4(x)\n",
        "    return F.log_softmax(x, dim=1)\n",
        "\n",
        "\n",
        "\n",
        "net = NeuralNet()\n",
        "net"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HeUVQ3iIpE33",
        "outputId": "f06be139-f5e1-4b9b-d5f7-fb166ce63d95"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NeuralNet(\n",
              "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
              "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
              "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  Defining metric\n",
        "def accuracy(validation_set):\n",
        "  lbs = []\n",
        "  preds = []\n",
        "  for im, lb in validation_set:\n",
        "    for l in lb:\n",
        "      lbs.append(l)\n",
        "    for i in im:\n",
        "      output = net(i)\n",
        "      _, ind = torch.max(output, dim=1)\n",
        "      preds.append(ind)\n",
        "  k=0\n",
        "  for j in range(len(lbs)):\n",
        "    if preds[j]==lbs[j]:\n",
        "      k+=1\n",
        "  return round(k/12000, 3)"
      ],
      "metadata": {
        "id": "N9nazp-ZdjiJ"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#  Training model\n",
        "import torch.optim as optim\n",
        "\n",
        "optimiser = optim.Adam(net.parameters(), lr=1e-4)\n",
        "\n",
        "epochs = 5\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for data, labels in train_dl:\n",
        "    #  zero gradients\n",
        "    net.zero_grad()\n",
        "    #  make predictions\n",
        "    predictions = net(data)\n",
        "    #  calculate loss\n",
        "    loss = F.nll_loss(predictions, labels)\n",
        "    #  compute gradients\n",
        "    loss.backward()\n",
        "    #  optimise gradients\n",
        "    optimiser.step()\n",
        "  #  print loss\n",
        "  print(f'Epoch [{epoch+1}/{epochs}]\\tLoss: {round(loss.item(), 6)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I0PsaHzIh3W",
        "outputId": "ed3d6bb0-61f3-4147-e864-968a855058ed"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5]\tLoss: 1.7e-05\n",
            "Epoch [2/5]\tLoss: 3e-06\n",
            "Epoch [3/5]\tLoss: 0.006239\n",
            "Epoch [4/5]\tLoss: 0.00524\n",
            "Epoch [5/5]\tLoss: 2e-06\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy(valid_dl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bmc8NoM94E9U",
        "outputId": "7787984c-7792-4c14-cf7a-797868afc112"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.975"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    }
  ]
}